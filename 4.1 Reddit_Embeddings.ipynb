{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lingua-language-detector\n",
      "  Downloading lingua_language_detector-2.0.2-cp311-none-win_amd64.whl (73.3 MB)\n",
      "     ---------------------------------------- 73.3/73.3 MB 9.8 MB/s eta 0:00:00\n",
      "Installing collected packages: lingua-language-detector\n",
      "Successfully installed lingua-language-detector-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install lingua-language-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:53<00:00, 11.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "import re\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "\n",
    "vocab = np.loadtxt('model_vocab.txt', dtype=str).tolist()\n",
    "\n",
    "db_path = \"Reddit Data/database.sqlite\"\n",
    "\n",
    "batch_size = 10000\n",
    "skip_gram = 1  # 0 for CBOW, 1 for skip-gram\n",
    "\n",
    "detector = LanguageDetectorBuilder.from_all_languages().build()\n",
    "\n",
    "print('init model')\n",
    "model = Word2Vec([vocab], vector_size=100, window=5, sg=skip_gram, epochs=1)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', str(text).lower()).split()\n",
    "\n",
    "def is_english(text):\n",
    "    detected_language = detector.detect_language_of(text)\n",
    "    return detected_language == Language.ENGLISH\n",
    "\n",
    "def train_model(chunk):\n",
    "    sentences = [preprocess_text(text) for text in chunk['body'] if is_english(text)]\n",
    "    model.train(sentences, total_examples=len(sentences), epochs=5)\n",
    "\n",
    "def fetch_and_train(low):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(f\"SELECT body FROM May2015 LIMIT {batch_size} OFFSET {low}\", conn)\n",
    "    conn.close()\n",
    "    train_model(df)\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT COUNT(*) FROM May2015\")\n",
    "# total_rows = cursor.fetchone()[0]\n",
    "total_rows = 100000\n",
    "conn.close()\n",
    "\n",
    "# Create a list of tasks for each batch\n",
    "tasks = [(low) for low in range(0, total_rows, batch_size)]\n",
    "\n",
    "# Use ProcessPoolExecutor to parallelize the tasks\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(fetch_and_train, tasks), total=len(tasks)))\n",
    "\n",
    "# Save the model\n",
    "if skip_gram == 0:\n",
    "    model.save(\"reddit_cbow.model\")\n",
    "else:\n",
    "    model.save(\"reddit_sg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of comments: 137.76\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "df = pd.read_sql_query(f\"SELECT body FROM May2015 LIMIT {10000} OFFSET {100000}\", conn)\n",
    "conn.close()\n",
    "average_length = df['body'].str.len().mean()\n",
    "print(f\"Average length of comments: {average_length:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
